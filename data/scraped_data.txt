Sign up Sign in Sign up Sign in Joe Osborne Follow -- 6 Listen Share Web scraping is my favorite area of coding. It’s both incredibly frustrating and extremely rewarding. The best thing about scraping is that the possibilities are endless. There’s virtually infinite data on the internet, and a lot of it is super easy to collect with a simple scraper. Getting started is very easy. When I began, I had only written a few lines of code in my entire life, but I had the idea to scrape mortgage interest rates to watch their trend in real time. After a quick Google search and about 20 minutes later, I had built my first web scraper. I want to help others do the same! I typically use either Python or JavaScript/TypeScript. Both are great options, it’s mostly a matter of preference. In this guide I’ll go over very simple examples for both. Prerequisites: That’s it! Let’s get started. Create a new folder on your machine and a new .js or .py file inside the folder. Let’s name them scraper-python.pyand scraper-javascript.js. Open up the folder in your IDE of choice. We’ll quickly download a couple libraries to help us out. If using Python, open up a terminal and run pip install requests and pip install beautifulsoup4 . If using JavaScript, run npm init and npm install cheerio . For TypeScript specifically, you should run npm install ts-node which will allow you to run the scraper later. Choose a website to scrape and make a network request to the website. For this guide, we’ll scrape example.com because it’s very simple and doesn’t have any blocking or authentication. Higher traffic sites like LinkedIn, Indeed, etc are notoriously difficult to scrape due to sophisticated bot detection. In our code, we’ll make a simple GET request to example.com. The website will send us back its HTML. In this step, we’ll just print the HTML to the console. Later, we’ll parse out specific pieces of it. Python: JavaScript: Go ahead and run your script by pasting either python scraper-python.py or node scraper-javascript.js in your terminal. Here’s the result you should get from printing the HTML: Nice! You made a network request to the website, and got back the HTML. Now, let’s parse out specific parts of the page. BeautifulSoup and cheerio are libraries that help us navigate HTML in code. They allow us to pass in certain paths and patterns to get certain snippets of HTML. Let’s go ahead and capture 3 things from this page: The title, the text, and the “More information…” link. We’ll use CSS Selectors to find these elements in the HTML. CSS Selectors are notations used to locate HTML elements, and they are very easy to learn. Here’s a cheatsheet you can use. The ones we will use for this guide are very simple, but it’s worth your time to get familiar with more complex ones when scraping real websites. Figuring out the right selector is usually not too hard, and I constantly use Google and ChatGPT to help me come up with good ones. Let’s capture the title, text, and extract the link from the <a> tag. Add these lines to your code. Python: JavaScript: After adding those lines to your script and running it, the console should print out this text: Congratulations! You have built a web scraper. Becoming proficient at web scraping opens up endless possibilities. Especially with the recent advent of AI, mass data collection is more valuable than ever. It’s also tons of fun and can be a rewarding hobby! -- -- 6 Hi! I'm a software engineer with early stage startup experience. Check out some of my work at https://joeosborne.me :) Help Status About Careers Press Blog Privacy Terms Text to speech Teams